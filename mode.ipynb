{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"train.csv\")\n",
    "# test_df = pd.read_csv(\"test.csv\")\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_images.reshape((50000,-1))\n",
    "print(X_train.shape)\n",
    "X_test = test_images.reshape((10000,-1))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels.flatten()\n",
    "y_test = test_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x>0).astype(float)\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z- np.max(z,axis=1, keepdims=True))\n",
    "    return exp_z/np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y,y_pred):\n",
    "    m=y.shape[0]\n",
    "    loss = - np.sum(y * np.log(y_pred+1e-8)) / m\n",
    "    return loss\n",
    "\n",
    "def weights_back_pro(X_train, y_train, iterations, learning_rate=0.01):\n",
    "    m,n = X_train.shape\n",
    "    layer2=32\n",
    "    weights_12 = np.random.randn(n,layer2) * 0.01\n",
    "    bias_12 = np.zeros((1,layer2))\n",
    "\n",
    "    layer3=32\n",
    "    weights_23 = np.random.randn(layer2, layer3) * 0.01\n",
    "    bias_23 = np.zeros((1,layer3))\n",
    "\n",
    "    output=10\n",
    "    weights_3o = np.random.randn(layer3, output) * 0.01\n",
    "    bias_3o = np.zeros((1,output))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        layer1_O = relu(np.dot(X_train, weights_12) + bias_12)\n",
    "        layer2_O = relu(np.dot(layer1_O, weights_23) + bias_23)\n",
    "        predictions = softmax(np.dot(layer2_O, weights_3o)+ bias_3o)\n",
    "        y_one_hot = np.zeros((m, output))\n",
    "        y_one_hot[np.arange(m), y_train] = 1\n",
    "        loss = cross_entropy_loss(y_one_hot, predictions)\n",
    "\n",
    "        print(f\"iteration{i}: Loss: {loss}\")\n",
    "        \n",
    "        weights_3o_grad = (1/m) * np.dot(layer2_O.T, (predictions-y_one_hot))\n",
    "        bias_3o_grad = (1/m) * np.sum(predictions-y_one_hot, axis=0, keepdims=True)\n",
    "        error_2 = np.dot((predictions - y_one_hot), weights_3o.T) * relu_derivative(layer2_O)\n",
    "\n",
    "        weights_23_grad = (1/m) * np.dot(layer1_O.T, error_2)\n",
    "        bias_23_grad = (1/m) * np.sum(error_2, axis=0, keepdims=True)\n",
    "        error_1 = np.dot(error_2, weights_23.T) * relu_derivative(layer1_O)\n",
    "\n",
    "        weights_12_grad = (1/m) * np.dot(X_train.T, error_1)\n",
    "        bias_12_grad = (1/m) * np.sum(error_1, axis=0, keepdims=True)\n",
    "\n",
    "        weights_3o -= learning_rate * weights_3o_grad\n",
    "        bias_3o -= learning_rate * bias_3o_grad\n",
    "        \n",
    "        weights_23 -= learning_rate * weights_23_grad\n",
    "        bias_23 -= learning_rate * bias_23_grad\n",
    "        \n",
    "        weights_12 -= learning_rate * weights_12_grad\n",
    "        bias_12 -= learning_rate * bias_12_grad\n",
    "    return weights_12, bias_12, weights_23, bias_23, weights_3o, bias_3o\n",
    "\n",
    "def predict(X, weights_1, biases_1, weights_2, biases_2, weights_3, biases_3):\n",
    "    layer_output_1 = relu(np.dot(X, weights_1) + biases_1)\n",
    "    layer_output_2 = relu(np.dot(layer_output_1, weights_2) + biases_2)\n",
    "    predictions = softmax(np.dot(layer_output_2, weights_3) + biases_3)\n",
    "    return np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0: Loss: 2.3150857376972462\n",
      "iteration1: Loss: 2.2981400105523226\n",
      "iteration2: Loss: 2.2908247628047755\n",
      "iteration3: Loss: 2.284950451480555\n",
      "iteration4: Loss: 2.278887219905517\n",
      "iteration5: Loss: 2.2720040228712652\n",
      "iteration6: Loss: 2.2639002405677906\n",
      "iteration7: Loss: 2.254257853986804\n",
      "iteration8: Loss: 2.2427499745277157\n",
      "iteration9: Loss: 2.229160006719492\n",
      "Test Accuracy: 18.98%\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "learning_rate = 0.01\n",
    "weights_1, biases_1, weights_2, biases_2, weights_3, biases_3 = weights_back_pro(X_train, y_train, iterations, learning_rate)\n",
    "\n",
    "y_pred = predict(X_train, weights_1, biases_1, weights_2, biases_2, weights_3, biases_3)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_train)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1012 - categorical_crossentropy: 23.1250 - loss: 23.1250 - val_accuracy: 0.1021 - val_categorical_crossentropy: 2.3030 - val_loss: 2.3030\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0978 - categorical_crossentropy: 2.3029 - loss: 2.3029 - val_accuracy: 0.0952 - val_categorical_crossentropy: 2.3030 - val_loss: 2.3030\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1001 - categorical_crossentropy: 2.3026 - loss: 2.3026 - val_accuracy: 0.0997 - val_categorical_crossentropy: 2.3030 - val_loss: 2.3030\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0987 - categorical_crossentropy: 2.3025 - loss: 2.3025 - val_accuracy: 0.0952 - val_categorical_crossentropy: 2.3031 - val_loss: 2.3031\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1016 - categorical_crossentropy: 2.3026 - loss: 2.3026 - val_accuracy: 0.0997 - val_categorical_crossentropy: 2.3027 - val_loss: 2.3027\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0991 - categorical_crossentropy: 2.3026 - loss: 2.3026 - val_accuracy: 0.0977 - val_categorical_crossentropy: 2.3027 - val_loss: 2.3027\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1025 - categorical_crossentropy: 2.3024 - loss: 2.3024 - val_accuracy: 0.0952 - val_categorical_crossentropy: 2.3028 - val_loss: 2.3028\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1046 - categorical_crossentropy: 2.3025 - loss: 2.3025 - val_accuracy: 0.0977 - val_categorical_crossentropy: 2.3026 - val_loss: 2.3026\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0970 - categorical_crossentropy: 2.3027 - loss: 2.3027 - val_accuracy: 0.0952 - val_categorical_crossentropy: 2.3027 - val_loss: 2.3027\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1041 - categorical_crossentropy: 2.3025 - loss: 2.3025 - val_accuracy: 0.0997 - val_categorical_crossentropy: 2.3026 - val_loss: 2.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fe9ef03650>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics= ['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "model.fit(X_train, y_train_one_hot, validation_split=0.2, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1006 - categorical_crossentropy: 2.3026 - loss: 2.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.302616596221924, 2.302616596221924, 0.10000000149011612]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
